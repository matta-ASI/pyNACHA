# -*- coding: utf-8 -*-
"""ACH/NACHA File Parser (.lob) to CSV

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uTrB5ca6fozmTFLi2OjNqJvSy10o2r4b
"""

# ach_parser.py
import json
import csv
import os
from datetime import datetime # For default file naming

# Define field mappings for each record type based on NACHA specifications.
# Positions are 0-indexed for Python string slicing.
# (Start Index, End Index, Description)
RECORD_DEFINITIONS = {
    '1': {  # File Header Record
        'record_type_code': (0, 1, "Record Type Code"),
        'priority_code': (1, 3, "Priority Code"),
        'immediate_destination': (3, 13, "Immediate Destination"),
        'immediate_origin': (13, 23, "Immediate Origin"),
        'file_creation_date_YYMMDD': (23, 29, "File Creation Date (YYMMDD)"),
        'file_creation_time_HHMM': (29, 33, "File Creation Time (HHMM)"),
        'file_id_modifier': (33, 34, "File ID Modifier"),
        'record_size': (34, 37, "Record Size (must be 094)"),
        'blocking_factor': (37, 39, "Blocking Factor (must be 10)"),
        'format_code': (39, 40, "Format Code (must be 1)"),
        'immediate_destination_name': (40, 63, "Immediate Destination Name"),
        'immediate_origin_name': (63, 86, "Immediate Origin Name"),
        'reference_code': (86, 94, "Reference Code")
    },
    '5': {  # Batch Header Record
        'record_type_code': (0, 1, "Record Type Code"),
        'service_class_code': (1, 4, "Service Class Code (200=Mixed, 220=Credits, 225=Debits)"),
        'company_name': (4, 20, "Company Name"),
        'company_discretionary_data': (20, 40, "Company Discretionary Data"),
        'company_identification': (40, 50, "Company Identification (EIN or DDA)"),
        'standard_entry_class_code': (50, 53, "Standard Entry Class Code (e.g., PPD, CCD)"),
        'company_entry_description': (53, 63, "Company Entry Description"),
        'company_descriptive_date_YYMMDD': (63, 69, "Company Descriptive Date (YYMMDD or other)"),
        'effective_entry_date_YYMMDD': (69, 75, "Effective Entry Date (YYMMDD)"),
        'settlement_date_julian': (75, 78, "Settlement Date (Julian)"), # Inserted by ACH Operator
        'originator_status_code': (78, 79, "Originator Status Code (1=DFI)"),
        'originating_dfi_identification_batch': (79, 87, "Originating DFI Identification (Routing Number)"),
        'batch_number': (87, 94, "Batch Number")
    },
    '6': {  # Entry Detail Record
        'record_type_code': (0, 1, "Record Type Code"),
        'transaction_code': (1, 3, "Transaction Code"),
        'receiving_dfi_identification': (3, 11, "Receiving DFI Identification (Routing Number, first 8 digits)"),
        'check_digit': (11, 12, "Check Digit (9th digit of routing number)"),
        'dfi_account_number': (12, 29, "DFI Account Number"),
        'amount_cents': (29, 39, "Amount (cents)"),
        'individual_identification_number': (39, 54, "Individual Identification Number (Receiver ID)"),
        'individual_name': (54, 76, "Individual Name (Receiver Name)"),
        'discretionary_data': (76, 78, "Discretionary Data (Payment Type Code)"),
        'addenda_record_indicator': (78, 79, "Addenda Record Indicator (0=No, 1=Yes)"),
        'trace_number': (79, 94, "Trace Number")
    },
    '7': {  # Addenda Record
        'record_type_code': (0, 1, "Record Type Code"),
        'addenda_type_code': (1, 3, "Addenda Type Code (e.g., 05 for payment related)"),
        'payment_related_information': (3, 83, "Payment Related Information"),
        'addenda_sequence_number': (83, 87, "Addenda Sequence Number"),
        'entry_detail_sequence_number': (87, 94, "Entry Detail Sequence Number")
    },
    '8': {  # Batch Control Record
        'record_type_code': (0, 1, "Record Type Code"),
        'service_class_code_control': (1, 4, "Service Class Code (matches Batch Header)"),
        'entry_addenda_count_batch': (4, 10, "Entry/Addenda Count"),
        'entry_hash_batch': (10, 20, "Entry Hash (Sum of RDFI ID numbers)"),
        'total_debit_entry_dollar_amount_batch_cents': (20, 32, "Total Debit Entry Dollar Amount (cents)"),
        'total_credit_entry_dollar_amount_batch_cents': (32, 44, "Total Credit Entry Dollar Amount (cents)"),
        'company_identification_control': (44, 54, "Company Identification (matches Batch Header)"),
        'message_authentication_code': (54, 73, "Message Authentication Code (MAC)"), # Optional
        'reserved_batch_control': (73, 79, "Reserved"),
        'originating_dfi_identification_batch_control': (79, 87, "Originating DFI Identification (matches Batch Header)"),
        'batch_number_control': (87, 94, "Batch Number (matches Batch Header)")
    },
    '9': {  # File Control Record
        'record_type_code': (0, 1, "Record Type Code"),
        'batch_count_file': (1, 7, "Batch Count"),
        'block_count_file': (7, 13, "Block Count (lines/10, rounded up)"),
        'entry_addenda_count_file': (13, 21, "Entry/Addenda Count"),
        'entry_hash_file': (21, 31, "Entry Hash (Sum of Entry Hash totals from Batch Control)"),
        'total_debit_entry_dollar_amount_file_cents': (31, 43, "Total Debit Entry Dollar Amount in File (cents)"),
        'total_credit_entry_dollar_amount_file_cents': (43, 55, "Total Credit Entry Dollar Amount in File (cents)"),
        'reserved_file_control': (55, 94, "Reserved")
    }
}

def parse_record(line):
    """Parses a single 94-character ACH record."""
    if not line or len(line) < 1:
        return None, None

    record_type = line[0]
    definition = RECORD_DEFINITIONS.get(record_type)

    if not definition:
        if record_type == '9' and all(c == '9' for c in line.strip()): # Common filler for last block
            return "filler", {"raw_line": line.strip()}
        # print(f"Warning: Unknown or unhandled record type '{record_type}' for line: {line.strip()}")
        return "unknown", {"raw_line": line.strip()}

    parsed = {}
    for field_name, (start, end, description) in definition.items():
        value = line[start:min(end, len(line))].strip()
        parsed[field_name] = value

        # Numerical conversions
        if field_name in ['amount_cents', 'total_debit_entry_dollar_amount_batch_cents',
                          'total_credit_entry_dollar_amount_batch_cents',
                          'entry_addenda_count_batch', 'entry_hash_batch',
                          'batch_count_file', 'block_count_file', 'entry_addenda_count_file', 'entry_hash_file',
                          'total_debit_entry_dollar_amount_file_cents',
                          'total_credit_entry_dollar_amount_file_cents']:
            try:
                parsed[field_name] = int(value) if value else 0
            except ValueError:
                # print(f"Warning: Could not convert field '{description}' value '{value}' to int. Keeping as string.")
                pass # Keep as string if conversion fails

    return record_type, parsed

def parse_ach_file_content(ach_content):
    """
    Parses the string content of an ACH file.
    """
    ach_data = {
        "file_header": None,
        "batches": [],
        "file_control": None,
        "errors": [],
        "other_records": []
    }
    current_batch = None
    current_entry = None
    lines = []

    if isinstance(ach_content, str):
        if '\n' in ach_content or '\r' in ach_content:
            lines = ach_content.splitlines()
        else:
            for i in range(0, len(ach_content), 94):
                chunk = ach_content[i:i+94]
                if chunk: # Ensure not adding empty strings if length isn't multiple of 94
                    lines.append(chunk)
    elif isinstance(ach_content, list):
        lines = ach_content
    else:
        ach_data["errors"].append("Invalid ACH content type. Expected string or list of strings.")
        return ach_data

    for i, line in enumerate(lines):
        line_number = i + 1
        original_line = line # Keep original before stripping for error reporting
        line = line.strip() # Process stripped line but check length of original for ACH compliance

        if not line: # Skip completely empty lines after strip
            continue

        # ACH records must be 94 characters. Allow filler lines of all '9's which might be shorter if at EOF.
        is_strict_filler = all(c == '9' for c in line)
        if len(original_line) != 94 and not is_strict_filler:
            ach_data["errors"].append(f"Line {line_number}: Expected 94 characters, got {len(original_line)}. Content: '{original_line}'")
            # Decide if to continue parsing this line or skip
            # For now, we attempt to parse it if it has content.

        record_type, parsed_record = parse_record(original_line) # Parse original line

        if not parsed_record:
            ach_data["errors"].append(f"Line {line_number}: Could not parse line. Content: '{original_line}'")
            continue

        if record_type == '1':
            ach_data['file_header'] = parsed_record
        elif record_type == '5':
            if current_batch:
                ach_data["errors"].append(f"Line {line_number}: Unexpected Batch Header. Previous batch not closed.")
            current_batch = parsed_record
            current_batch['entries'] = []
            ach_data['batches'].append(current_batch)
            current_entry = None # Reset current_entry when a new batch starts
        elif record_type == '6':
            if not current_batch:
                ach_data["errors"].append(f"Line {line_number}: Entry Detail Record found outside of a batch.")
                # Optionally create a dummy batch or skip
                continue
            current_entry = parsed_record
            current_entry['addenda'] = []
            current_batch['entries'].append(current_entry)
        elif record_type == '7':
            if not current_entry: # Addenda must follow an entry
                # Try to associate with the last entry of the current batch if available
                if current_batch and current_batch['entries']:
                    # print(f"Warning: Line {line_number}: Addenda Record found without an immediately preceding Entry Detail. Associating with last entry in batch.")
                    current_batch['entries'][-1]['addenda'].append(parsed_record)
                else:
                    ach_data["errors"].append(f"Line {line_number}: Addenda Record found without a preceding Entry Detail or active batch.")
                    continue
            else:
                 current_entry['addenda'].append(parsed_record)
        elif record_type == '8':
            if not current_batch:
                ach_data["errors"].append(f"Line {line_number}: Batch Control Record found outside of a batch context.")
                continue
            current_batch['batch_control'] = parsed_record
            current_batch = None
            current_entry = None
        elif record_type == '9': # File Control or filler
            # Check if it's a genuine File Control or just a filler line of 9s
            if 'batch_count_file' in parsed_record: # Heuristic: if it has file control specific fields
                ach_data['file_control'] = parsed_record
            elif parsed_record.get("raw_line") and all(c == '9' for c in parsed_record["raw_line"]):
                 ach_data['other_records'].append({"type": "filler", "data": parsed_record, "line": line_number})
            else: # If it starts with '9' but doesn't look like filler or known file control
                ach_data["errors"].append(f"Line {line_number}: Ambiguous record type '9'. Parsed as: {parsed_record}")
                ach_data['other_records'].append({"type": "ambiguous_9", "data": parsed_record, "line": line_number})


        elif record_type == "filler":
            ach_data['other_records'].append({"type": "filler", "data": parsed_record, "line": line_number})
        elif record_type == "unknown":
            ach_data['other_records'].append({"type": "unknown", "data": parsed_record, "line": line_number})
            # ach_data["errors"].append(f"Line {line_number}: Encountered an unknown record type. Data: {parsed_record}")
    return ach_data

def parse_ach_lob_file(file_path):
    """
    Reads an ACH file (potentially from a .lob DB2 export) and parses its content.
    """
    try:
        with open(file_path, 'r', encoding='ascii', errors='ignore') as f:
            content = f.read()
    except FileNotFoundError:
        return {"errors": [f"Error: File not found at {file_path}"]}
    except Exception as e:
        return {"errors": [f"Error reading file {file_path}: {e}"]}

    if not content.strip(): # Check if file is empty or whitespace only
        return {"errors": [f"File {file_path} is empty or contains only whitespace."]}

    return parse_ach_file_content(content)

def write_ach_data_to_csv(parsed_ach_data, csv_file_path):
    """
    Writes parsed ACH entry details to a CSV file.
    """
    if not parsed_ach_data or not parsed_ach_data.get("batches"):
        print("No batch data found to write to CSV.")
        if parsed_ach_data.get("errors"):
             print("Parsing errors occurred:")
             for err in parsed_ach_data["errors"]: print(f"- {err}")
        return False

    # Define CSV headers
    # These should correspond to the keys you'll be extracting for each row
    headers = [
        # File Header Info
        'file_creation_date_YYMMDD', 'file_creation_time_HHMM',
        'immediate_destination_name', 'immediate_origin_name', 'file_id_modifier',
        # Batch Header Info
        'batch_service_class_code', 'company_name', 'company_identification',
        'standard_entry_class_code', 'company_entry_description', 'effective_entry_date_YYMMDD',
        'originating_dfi_identification_batch', 'batch_number',
        # Entry Detail Info
        'entry_transaction_code', 'receiving_dfi_identification', 'entry_check_digit',
        'dfi_account_number', 'amount_cents', 'amount_dollars',
        'individual_identification_number', 'individual_name',
        'entry_discretionary_data', 'addenda_record_indicator', 'entry_trace_number',
        # Addenda Info (from first addenda, if present)
        'addenda_type_code', 'payment_related_information'
    ]

    file_header = parsed_ach_data.get('file_header', {})

    try:
        with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=headers)
            writer.writeheader()

            for batch in parsed_ach_data.get('batches', []):
                batch_header = batch # Batch record itself is the header
                for entry in batch.get('entries', []):
                    row = {
                        # File Header Data
                        'file_creation_date_YYMMDD': file_header.get('file_creation_date_YYMMDD'),
                        'file_creation_time_HHMM': file_header.get('file_creation_time_HHMM'),
                        'immediate_destination_name': file_header.get('immediate_destination_name'),
                        'immediate_origin_name': file_header.get('immediate_origin_name'),
                        'file_id_modifier': file_header.get('file_id_modifier'),

                        # Batch Header Data
                        'batch_service_class_code': batch_header.get('service_class_code'),
                        'company_name': batch_header.get('company_name'),
                        'company_identification': batch_header.get('company_identification'),
                        'standard_entry_class_code': batch_header.get('standard_entry_class_code'),
                        'company_entry_description': batch_header.get('company_entry_description'),
                        'effective_entry_date_YYMMDD': batch_header.get('effective_entry_date_YYMMDD'),
                        'originating_dfi_identification_batch': batch_header.get('originating_dfi_identification_batch'),
                        'batch_number': batch_header.get('batch_number'),

                        # Entry Detail Data
                        'entry_transaction_code': entry.get('transaction_code'),
                        'receiving_dfi_identification': entry.get('receiving_dfi_identification'),
                        'entry_check_digit': entry.get('check_digit'),
                        'dfi_account_number': entry.get('dfi_account_number'),
                        'amount_cents': entry.get('amount_cents'),
                        'amount_dollars': "{:.2f}".format(entry.get('amount_cents', 0) / 100.0) if entry.get('amount_cents') is not None else "0.00",
                        'individual_identification_number': entry.get('individual_identification_number'),
                        'individual_name': entry.get('individual_name'),
                        'entry_discretionary_data': entry.get('discretionary_data'),
                        'addenda_record_indicator': entry.get('addenda_record_indicator'),
                        'entry_trace_number': entry.get('trace_number'),
                    }

                    # Addenda Data (from first addenda if it exists)
                    first_addenda = entry.get('addenda', [{}])[0] # Get first addenda or empty dict
                    row['addenda_type_code'] = first_addenda.get('addenda_type_code')
                    row['payment_related_information'] = first_addenda.get('payment_related_information')

                    writer.writerow(row)
        print(f"Successfully wrote ACH data to {csv_file_path}")
        return True
    except IOError as e:
        print(f"Error writing CSV file: {e}")
        return False
    except Exception as e:
        print(f"An unexpected error occurred during CSV writing: {e}")
        return False

if __name__ == '__main__':
    print("ACH (.lob) File to CSV Converter")

    input_lob_file = input("Enter the path to your input .lob file: ").strip()

    # Suggest a default output CSV name based on the input file name
    base_name = os.path.splitext(os.path.basename(input_lob_file))[0]
    default_csv_file = f"{base_name}_ach_details_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    output_csv_file = input(f"Enter the path for the output CSV file (default: {default_csv_file}): ").strip()
    if not output_csv_file:
        output_csv_file = default_csv_file

    if not os.path.exists(input_lob_file):
        print(f"Error: Input file '{input_lob_file}' not found.")
    else:
        print(f"\nParsing '{input_lob_file}'...")
        parsed_data = parse_ach_lob_file(input_lob_file)

        if parsed_data.get("errors"):
            print("\n--- Parsing Errors/Warnings ---")
            for error in parsed_data["errors"]:
                print(f"- {error}")
            print("--- End of Errors/Warnings ---")

        # Optionally print a summary of parsed data structure (can be verbose)
        # print("\n--- Parsed ACH Data Summary ---")
        # if parsed_data.get("file_header"): print("File Header: Found")
        # print(f"Batches: {len(parsed_data.get('batches', []))}")
        # for i, batch in enumerate(parsed_data.get('batches', [])):
        #     print(f"  Batch {i+1} Entries: {len(batch.get('entries', []))}")
        # if parsed_data.get("file_control"): print("File Control: Found")
        # if parsed_data.get("other_records"): print(f"Other/Filler Records: {len(parsed_data.get('other_records',[]))}")
        # print("--- End of Summary ---")


        if parsed_data and not parsed_data.get("errors") or (parsed_data and parsed_data.get("batches")): # Proceed if some data parsed, even with errors
            print(f"\nWriting data to '{output_csv_file}'...")
            write_ach_data_to_csv(parsed_data, output_csv_file)
        else:
            print("\nNo data to write to CSV due to parsing issues or empty file content.")

    # Example of how to create a dummy .lob file for testing if you don't have one:
    # To test, you could uncomment the following lines to create 'test_ach_file.lob'
    # dummy_ach_content = (
    #     "101100000001234567890BANK OF AMERICA TEST BANK         24052912001094101DEST NAME              ORIGIN NAME            REF CODE\n"
    #     "5200COMPANY NAME      COMPANY DISCR DATA  1234567890PPDCOMPANY DESCRIP  2405292405291501ORIGIN_DFI_IDBATCH001\n"
    #     "632123456781ACCOUNTNUM12345   0000100000INDIVIDUAL ID  RECEIVER NAME         01TRACE_NUMBER_ENTRY_1\n"
    #     "705PAYMENT INFO FOR ENTRY 1                                                 0001TRACE_NUMBER_ENTRY_1\n"
    #     "637123456782ACCOUNTNUM67890   0000050000OTHER ID        OTHER NAME            00TRACE_NUMBER_ENTRY_2\n"
    #     "8200000003000000000000001500000000000000COMPANY ID  MAC                 ORIGIN_DFI_IDBATCH001\n"
    #     "90000010000010000000400000000000000000000150000                                           \n"
    #     "9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999\n"
    # )
    # test_lob_file_for_manual_run = "test_ach_file.lob"
    # with open(test_lob_file_for_manual_run, 'w', encoding='ascii') as f:
    #     f.write(dummy_ach_content)
    # print(f"\n(Dummy file '{test_lob_file_for_manual_run}' created for testing if you need it. You can enter this path.)")