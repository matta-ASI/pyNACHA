# -*- coding: utf-8 -*-
"""ACH to CSV Parser

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m4R5ax4broOUWOrjllwIQtJB0S40stPF
"""

import csv
import os

# --- ACH Record Field Definitions ---
# IMPORTANT: YOU MUST VERIFY AND COMPLETE THESE DEFINITIONS
#            BASED ON THE NACHA ACH FILE DETAILS DOCUMENTATION.
# Format: "RecordTypeCode": [("FieldName", start_index, end_index), ...]
# Indices are 0-based, end_index is exclusive (standard Python slicing).
# Each ACH record is typically 94 characters long.

ACH_RECORD_SPECS = {
    "1": [  # File Header Record (Record Type Code '1')
        ("record_type_code", 0, 1),
        ("priority_code", 1, 3),
        ("immediate_destination", 3, 13),
        ("immediate_origin", 13, 23),
        ("file_creation_date", 23, 29), # YYMMDD
        ("file_creation_time", 29, 33), # HHMM (optional)
        ("file_id_modifier", 33, 34),
        ("record_size", 34, 37), # Should be '094'
        ("blocking_factor", 37, 39), # Should be '10'
        ("format_code", 39, 40), # Should be '1'
        ("immediate_destination_name", 40, 63),
        ("immediate_origin_name", 63, 86),
        ("reference_code", 86, 94),
        # Example: ("your_custom_field_name", start_pos, end_pos),
        # TODO: Verify and complete ALL fields from NACHA spec for File Header
    ],
    "5": [  # Company/Batch Header Record (Record Type Code '5')
        ("record_type_code", 0, 1),
        ("service_class_code", 1, 4), # e.g., 200 (Mixed), 220 (Credits), 225 (Debits)
        ("company_name", 4, 20),
        ("company_discretionary_data", 20, 40),
        ("company_identification", 40, 50), # ODFI's routing for CR, Tax ID for DR
        ("standard_entry_class_code", 50, 53), # e.g., PPD, CCD, CTX, WEB, TEL
        ("company_entry_description", 53, 63),
        ("company_descriptive_date", 63, 69), # YYMMDD (optional)
        ("effective_entry_date", 69, 75), # YYMMDD
        ("settlement_date_julian", 75, 78), # Inserted by ACH Operator (Julian date format)
        ("originator_status_code", 78, 79), # Usually '1' for ODFI
        ("originating_dfi_identification", 79, 87), # First 8 digits of ODFI routing number
        ("batch_number", 87, 94),
        # TODO: Verify and complete ALL fields from NACHA spec for Company/Batch Header
    ],
    "6": [  # Entry Detail Record (Record Type Code '6')
        ("record_type_code", 0, 1),
        ("transaction_code", 1, 3), # e.g., 22 (Credit Checking), 27 (Debit Checking)
        ("receiving_dfi_identification", 3, 11), # First 8 digits of RDFI routing number
        ("check_digit", 11, 12), # 9th digit of RDFI routing number
        ("dfi_account_number", 12, 29), # Receiver's account number
        ("amount", 29, 39), # Amount in cents (e.g., 0000123450 is $123.45)
        ("individual_identification_number", 39, 54), # Receiver's ID (optional, can be agreement #)
        ("individual_name", 54, 76), # Receiver's Name
        ("discretionary_data", 76, 78), # Optional, usage varies by SEC code (e.g., payment type for WEB)
        ("addenda_record_indicator", 78, 79), # '0' for no addenda, '1' if addenda record follows
        ("trace_number_originating_dfi_part", 79, 87), # Originating DFI ID (first 8 of routing) from record '5'
        ("trace_number_sequence_part", 87, 94), # Sequentially assigned number by Originator
        # TODO: Verify and complete ALL fields from NACHA spec for Entry Detail
    ],
    "7": [  # Addenda Record (Record Type Code '7')
        ("record_type_code", 0, 1),
        ("addenda_type_code", 1, 3), # e.g., '05' for payment related info, '98' for NOC, '99' for Return
        ("payment_related_information", 3, 83), # Content varies by Addenda Type Code & SEC Code
        ("addenda_sequence_number", 83, 87), # For multiple addenda for one entry (usually 1)
        ("entry_detail_sequence_number", 87, 94), # Last 7 digits of trace number from preceding '6' record
        # TODO: Verify and complete ALL fields from NACHA spec for Addenda
    ],
    "8": [  # Company/Batch Control Record (Record Type Code '8')
        ("record_type_code", 0, 1),
        ("service_class_code", 1, 4), # Must match corresponding '5' record
        ("entry_addenda_count", 4, 10), # Total count of '6' and '7' records in batch
        ("entry_hash", 10, 20), # Sum of RDFI numbers (first 8 digits) from all '6' records in batch
        ("total_debit_entry_dollar_amount", 20, 32), # Total debit amount in batch (cents)
        ("total_credit_entry_dollar_amount", 32, 44), # Total credit amount in batch (cents)
        ("company_identification", 44, 54), # Must match corresponding '5' record
        ("message_authentication_code", 54, 73), # Optional, usually blank spaces
        ("reserved", 73, 79), # Blank spaces
        ("originating_dfi_identification", 79, 87), # Must match corresponding '5' record
        ("batch_number", 87, 94), # Must match corresponding '5' record
        # TODO: Verify and complete ALL fields from NACHA spec for Company/Batch Control
    ],
    "9": [  # File Control Record (Record Type Code '9')
        ("record_type_code", 0, 1),
        ("batch_count", 1, 7), # Total count of '5' records (batches) in file
        ("block_count", 7, 13), # Total records in file / blocking factor (usually 10)
        ("entry_addenda_count", 13, 21), # Total count of '6' and '7' records in file
        ("entry_hash_total", 21, 31), # Sum of all 'Entry Hash' totals from '8' records in file
        ("total_file_debit_entry_dollar_amount", 31, 43), # Total debit amount in file (cents)
        ("total_file_credit_entry_dollar_amount", 43, 55), # Total credit amount in file (cents)
        ("reserved", 55, 94), # Blank spaces
        # TODO: Verify and complete ALL fields from NACHA spec for File Control
    ],
}

def parse_ach_line(line, record_spec):
    """
    Parses a single line of an ACH file based on the provided record specification.
    Args:
        line (str): A single line (record) from the ACH file.
        record_spec (list): A list of tuples, where each tuple defines a field:
                              ("FieldName", start_index, end_index).
    Returns:
        dict: A dictionary where keys are field names and values are the extracted data.
    """
    record = {}
    for field_name, start, end in record_spec:
        # Ensure the line is long enough for the slice to prevent IndexError
        if len(line) >= end:
            record[field_name] = line[start:end].strip() # .strip() removes leading/trailing whitespace
        else:
            # Handle lines that are unexpectedly short for a defined field
            record[field_name] = "" # Assign empty string or some other placeholder
            # Optionally, log a warning for short lines if strict validation is needed:
            # print(f"Warning: Line too short for field '{field_name}'. Expected end {end}, got len {len(line)}. Line: '{line[:30]}...'")
    return record

def ach_to_csv(lob_file_path, output_dir="ach_csv_output"):
    """
    Parses an ACH (.lob) file and creates separate CSV files for each record type.
    Args:
        lob_file_path (str): The path to the input .lob (ACH) file.
        output_dir (str): The directory where the output CSV files will be saved.
                          This directory will be created if it doesn't exist.
    """
    if not os.path.exists(lob_file_path):
        print(f"Error: Input file not found at '{lob_file_path}'")
        return

    if not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir)
            print(f"Created output directory: '{output_dir}'")
        except OSError as e:
            print(f"Error creating output directory '{output_dir}': {e}")
            return

    # Dictionary to store lists of parsed records for each record type
    all_parsed_records = {rectype: [] for rectype in ACH_RECORD_SPECS.keys()}
    unknown_format_records = [] # To store lines that don't match expected record types

    try:
        # ACH files are often ASCII or EBCDIC. Python's default 'utf-8' might fail.
        # Try 'ascii', then 'latin-1' (which handles many 8-bit encodings) as common fallbacks.
        # If EBCDIC, a specific EBCDIC codec (e.g., 'cp500', 'cp037') or pre-conversion would be needed.
        encodings_to_try = ['ascii', 'latin-1', 'utf-8']
        file_content_lines = None

        for encoding in encodings_to_try:
            try:
                with open(lob_file_path, 'r', encoding=encoding) as lob_file:
                    file_content_lines = lob_file.readlines()
                print(f"Successfully read file with encoding: {encoding}")
                break # Stop if reading succeeds
            except UnicodeDecodeError:
                print(f"Warning: Could not decode file with encoding '{encoding}'. Trying next...")

        if file_content_lines is None:
            print(f"Error: Failed to decode file '{lob_file_path}' with tried encodings. "
                  "The file might be in an EBCDIC format or another unsupported encoding.")
            return

        line_number = 0
        for line in file_content_lines:
            line_number += 1
            line = line.rstrip('\n\r') # Remove newline characters

            if not line: # Skip empty lines
                continue

            # Standard ACH records are 94 characters. Add a check if strict validation is needed.
            # if len(line) != 94:
            #     print(f"Warning: Line {line_number} has length {len(line)}, expected 94. Content: '{line[:30]}...'")

            record_type_code = line[0] if line else None

            if record_type_code in ACH_RECORD_SPECS:
                record_specification = ACH_RECORD_SPECS[record_type_code]
                parsed_data = parse_ach_line(line, record_specification)
                all_parsed_records[record_type_code].append(parsed_data)
            else:
                unknown_format_records.append({"line_number": line_number, "data": line})
                # print(f"Warning: Unknown record type code '{record_type_code}' on line {line_number}. Line: '{line[:30]}...'")

    except FileNotFoundError: # This check is a bit redundant due to the initial check, but good practice
        print(f"Error: The file '{lob_file_path}' was not found (should have been caught earlier).")
        return
    except Exception as e:
        print(f"An unexpected error occurred while reading or processing the file: {e}")
        return

    # Write collected records to their respective CSV files
    for record_type_code, list_of_records in all_parsed_records.items():
        if list_of_records: # Only create a CSV if records of this type were found
            # Define field names from the spec for the CSV header
            field_names = [field[0] for field in ACH_RECORD_SPECS[record_type_code]]

            # Sanitize record_type_code for filename if it could be non-alphanumeric
            safe_record_type_code = ''.join(filter(str.isalnum, str(record_type_code)))
            csv_file_name = f"ach_type_{safe_record_type_code}_records.csv"
            csv_file_path = os.path.join(output_dir, csv_file_name)

            try:
                with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:
                    writer = csv.DictWriter(csv_file, fieldnames=field_names)
                    writer.writeheader()
                    writer.writerows(list_of_records)
                print(f"Successfully created '{csv_file_path}' with {len(list_of_records)} records.")
            except IOError as e:
                print(f"Error writing CSV file '{csv_file_path}': {e}")
            except Exception as e:
                print(f"An unexpected error occurred while writing '{csv_file_path}': {e}")

    if unknown_format_records:
        unknown_csv_path = os.path.join(output_dir, "unknown_format_records.csv")
        try:
            with open(unknown_csv_path, 'w', newline='', encoding='utf-8') as csv_file:
                # Define headers for the unknown records CSV
                fieldnames = ["line_number", "data"]
                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(unknown_format_records)
            print(f"Found {len(unknown_format_records)} records with unknown format. Saved details to '{unknown_csv_path}'")
        except IOError as e:
            print(f"Error writing unknown records CSV file '{unknown_csv_path}': {e}")

# --- How to use the script ---
if __name__ == "__main__":
    # 1. IMPORTANT: Update ACH_RECORD_SPECS above with the correct field definitions
    #    for your specific ACH file format, based on NACHA guidelines.

    # 2. Set the path to your input .lob file
    input_lob_file_path = "your_ach_file.lob"  # <--- !!! CHANGE THIS TO YOUR ACTUAL .LOB FILE PATH !!!

    # 3. Set the directory where you want the CSV files to be saved
    output_csv_directory = "ach_parsed_csvs"    # <--- You can change this if needed

    print("Starting ACH file parsing process...")
    print("======================================================================")
    print("IMPORTANT REMINDER:")
    print("Please ensure the field definitions in the 'ACH_RECORD_SPECS' dictionary")
    print("at the top of this script are accurately completed according to the")
    print("NACHA documentation for YOUR specific ACH file format. The current")
    print("definitions are examples and may need significant adjustments.")
    print("======================================================================")

    ach_to_csv(input_lob_file_path, output_csv_directory)

    print("\nACH file parsing process complete.")
    print(f"Output CSV files should be in the '{output_csv_directory}' directory (if any records were processed).")